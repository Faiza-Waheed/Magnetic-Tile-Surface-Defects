epoch,Training Loss,Validation Loss
1,0.9481997,0.9425154
2,0.9412261,0.9371098
3,0.93508977,0.9318855
4,0.9269568,0.9266346
5,0.9227652,0.9199262
6,0.91700095,0.9173778
7,0.9082079,0.9104805
8,0.9036403,0.8975442
9,0.89332587,0.88982874
10,0.88738525,0.8836222
11,0.88106567,0.87832904
12,0.87422806,0.8703331
13,0.8683946,0.8647725
14,0.86212075,0.8584161
15,0.8563434,0.8529601
16,0.8508882,0.84738857
17,0.84537446,0.8420403
18,0.8401837,0.8370183
19,0.835173,0.8325153
20,0.8305211,0.82764053
21,0.82588416,0.82310104
22,0.8212595,0.8187589
23,0.81705964,0.81472176
24,0.8130906,0.8108221
25,0.8091515,0.80687004
26,0.8053762,0.80327404
27,0.80173737,0.7996664
28,0.7983066,0.79629564
29,0.7950059,0.7930783
30,0.7918166,0.7899884
31,0.7887842,0.7870257
32,0.78586453,0.7841973
33,0.78307724,0.78146046
34,0.7803935,0.77886385
35,0.7778306,0.7763495
36,0.77536017,0.773936
37,0.7729869,0.7716319
38,0.770724,0.7694126
39,0.7685454,0.76729035
40,0.7664474,0.76524454
41,0.7644458,0.76327586
42,0.76251453,0.7613897
43,0.7606664,0.75957626
44,0.75887406,0.75783193
45,0.75713634,0.7561523
46,0.75549406,0.75453866
47,0.75389713,0.7529831
48,0.75237423,0.75148624
49,0.750904,0.75004476
50,0.749471,0.74865663
51,0.74811625,0.7473164
52,0.74679047,0.74602574
53,0.7455156,0.7447801
54,0.74428546,0.74357826
55,0.743106,0.74241847
56,0.7419684,0.7412981
57,0.74085975,0.7402167
58,0.73979765,0.7391716
59,0.7387498,0.7381603
60,0.73775935,0.73718333
61,0.7368039,0.73623884
62,0.7358569,0.7353241
63,0.7349692,0.7344392
64,0.73409224,0.73358214
65,0.73324406,0.73275214
66,0.7324271,0.73194784
67,0.7316274,0.7311687
68,0.73086566,0.73041314
69,0.7301183,0.7296806
70,0.7293902,0.7289697
71,0.7286904,0.7282802
72,0.72801346,0.72761077
73,0.72735435,0.72696084
74,0.7267026,0.72632986
75,0.7260783,0.72571665
76,0.7254763,0.7251207
77,0.72488564,0.72454154
78,0.72431237,0.72397876
79,0.72375935,0.7234312
80,0.72322106,0.72289896
81,0.72269255,0.7223805
82,0.72217447,0.72187585
83,0.721683,0.7213853
84,0.72118974,0.7209067
85,0.72071505,0.720441
86,0.72025883,0.7199872
87,0.7198105,0.7195449
88,0.7193703,0.719114
89,0.71894556,0.71869385
90,0.7185317,0.7182844
91,0.7181263,0.7178846
92,0.71773195,0.71749496
93,0.7173406,0.7171143
94,0.71696293,0.7167431
95,0.71659964,0.71638066
96,0.7162409,0.7160266
97,0.7158897,0.71568114
98,0.7155478,0.71534365
99,0.71520865,0.7150138
100,0.7148852,0.71469146
